{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7973263",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4a1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import moviepy.editor as mpy\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "from numpy.random import randint\n",
    "from numpy.random import randn\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import L1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faefd808",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d2322f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive training samples before removing outliers: 36\n",
      "Number of unlabelled training samples before removing outliers: 225\n",
      "Number of positive training samples after removing outliers: 35\n",
      "Number of unlabelled training samples after removing outliers: 195\n"
     ]
    }
   ],
   "source": [
    "Xy_train_file = './Datasets/Outputs/Xy_train.csv'\n",
    "Xy_train = pd.read_csv(Xy_train_file, index_col=False)\n",
    "\n",
    "# split the training dataset based on the label column\n",
    "Xy_train_positive = Xy_train.loc[Xy_train['label']==1]\n",
    "Xy_train_unlabelled = Xy_train.loc[Xy_train['label']==0]\n",
    "print('Number of positive training samples before removing outliers:', Xy_train_positive.shape[0])\n",
    "print('Number of unlabelled training samples before removing outliers:', Xy_train_unlabelled.shape[0])\n",
    "\n",
    "features_label_list = Xy_train.columns.tolist()\n",
    "num_features_list = []\n",
    "cat_features_list = []\n",
    "\n",
    "for column in features_label_list:\n",
    "    if column.startswith('Intrusions_') or column.startswith('MetamorphicFacies') or column.startswith('RockUnits'):\n",
    "        cat_features_list.append(column)\n",
    "    else:\n",
    "        num_features_list.append(column)\n",
    "\n",
    "num_features = Xy_train[num_features_list]\n",
    "cat_features = Xy_train[cat_features_list]\n",
    "\n",
    "# remove outliers\n",
    "Xy_train_positive_num = Xy_train_positive[num_features_list]\n",
    "Xy_train_unlabelled_num = Xy_train_unlabelled[num_features_list]\n",
    "\n",
    "Xy_train_positive_num_out_ind = (np.abs(stats.zscore(Xy_train_positive_num.drop(columns=['label']))) < 3).all(axis=1)\n",
    "Xy_train_unlabelled_num_out_ind = (np.abs(stats.zscore(Xy_train_unlabelled_num.drop(columns=['label']))) < 3).all(axis=1)\n",
    "\n",
    "Xy_train_positive_num_out_ind = Xy_train_positive_num_out_ind.index[Xy_train_positive_num_out_ind == False].tolist()\n",
    "Xy_train_unlabelled_num_out_ind = Xy_train_unlabelled_num_out_ind.index[Xy_train_unlabelled_num_out_ind == False].tolist()\n",
    "Xy_train_out = Xy_train_positive_num_out_ind + Xy_train_unlabelled_num_out_ind\n",
    "\n",
    "Xy_train_positive_num = Xy_train_positive_num.drop(index=Xy_train_positive_num_out_ind)\n",
    "Xy_train_unlabelled_num = Xy_train_unlabelled_num.drop(index=Xy_train_unlabelled_num_out_ind)\n",
    "\n",
    "print('Number of positive training samples after removing outliers:', Xy_train_positive_num.shape[0])\n",
    "print('Number of unlabelled training samples after removing outliers:', Xy_train_unlabelled_num.shape[0])\n",
    "\n",
    "Xy_train_num = pd.concat([Xy_train_positive_num, Xy_train_unlabelled_num]).reset_index(drop=True)\n",
    "Xy_train_num = Xy_train_num.to_numpy()\n",
    "features_num = Xy_train_num[:, :-1]\n",
    "labels_num = Xy_train_num[:, -1]\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_sm, y_sm = smote.fit_resample(features_num, labels_num)\n",
    "smote_samples = np.concatenate((X_sm, y_sm.reshape(-1, 1)), axis=1)\n",
    "X_positive = smote_samples[np.where(smote_samples[:, -1]==1)]\n",
    "X_positive = X_positive[:, 0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3903a",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2072e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(n_inputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(n_inputs*10), activation='LeakyReLU', activity_regularizer=L1(learning_rate), kernel_initializer='he_uniform', input_dim=n_inputs))\n",
    "    model.add(Dense(1, activation='sigmoid', activity_regularizer=L1(learning_rate)))\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(n_outputs*5), activation='LeakyReLU', activity_regularizer=L1(learning_rate), kernel_initializer='he_uniform', input_dim=latent_dim))\n",
    "    model.add(Dense(n_outputs, activation='linear', activity_regularizer=L1(learning_rate)))\n",
    "    return model\n",
    "\n",
    "# define the combined generator and discriminator model for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the discriminator\n",
    "    model.add(discriminator)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "n_samples = int(features_num.shape[0]-(2*labels_num.sum()))\n",
    "# sample real data\n",
    "def sample_real_data(n=n_samples):\n",
    "    X_rand = X_positive[randint(X_positive.shape[0], size=n), :]\n",
    "    y_rand = ones((n, 1))\n",
    "    return X_rand, y_rand\n",
    "\n",
    "# generate points in the latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n=n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# use the generator to generate n fake examples with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n=n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = generate_latent_points(latent_dim, n)\n",
    "    # predict outputs\n",
    "    X_fake = generator.predict(x_input, verbose=0)\n",
    "    # create class labels\n",
    "    y_fake = zeros((n, 1))\n",
    "    return X_fake, y_fake\n",
    "\n",
    "# evaluate the discriminator\n",
    "def summarize_performance(epoch, generator, discriminator, latent_dim):\n",
    "    # sample real data\n",
    "    x_real, y_real = sample_real_data()\n",
    "    # evaluate the discriminator on real examples\n",
    "    _, acc_real = discriminator.evaluate(X_sm, y_sm, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(generator, latent_dim)\n",
    "    # evaluate the discriminator on fake examples\n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "    return x_real, x_fake, acc_real, acc_fake\n",
    "\n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs, n_batch=128, n_eval=100):\n",
    "    # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "    acc_real_all = []\n",
    "    acc_fake_all = []\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # prepare real samples\n",
    "        x_real, y_real = sample_real_data(half_batch)\n",
    "        # prepare fake examples\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # update discriminator\n",
    "        d_model.train_on_batch(x_real, y_real)\n",
    "        d_model.train_on_batch(x_fake, y_fake)\n",
    "        # prepare points in the latent space as input for the generator\n",
    "        x_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = ones((n_batch, 1))\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "        \n",
    "        # plot data points\n",
    "        # ----------------\n",
    "        # evaluate the model every n_eval epochs\n",
    "        if (i+1) % n_eval == 0:\n",
    "            # summarize discriminator performance\n",
    "            x_real, x_fake, acc_real, acc_fake = summarize_performance(i, g_model, d_model, latent_dim)\n",
    "            print(i+1, acc_real, acc_fake)\n",
    "#             x_max = x_real[:, 1].max()\n",
    "#             x_min = x_real[:, 1].min()\n",
    "#             y_max = x_real[:, 12].max()\n",
    "#             y_min = x_real[:, 12].min()\n",
    "#             z_max = x_real[:, 7].max()\n",
    "#             z_min = x_real[:, 7].min()\n",
    "\n",
    "#             x_max = 2\n",
    "#             x_min = -0.5\n",
    "#             y_max = 2\n",
    "#             y_min = -1\n",
    "#             z_max = 1\n",
    "#             z_min = -3\n",
    "\n",
    "            # scatter plot real and fake data points\n",
    "#             fig = plt.figure(figsize=(18, 6))\n",
    "#             fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=-0.1, hspace=None)\n",
    "#             ax1 = fig.add_subplot(1, 2, 1)\n",
    "#             ax1.scatter(x_real[:, 1], x_real[:, 2], c='darkorange', alpha=0.5)\n",
    "#             ax1.scatter(x_fake[:, 1], x_fake[:, 2], c='navy', alpha=0.5)\n",
    "#             ax1.set_facecolor('whitesmoke')\n",
    "#             ax1.grid(linestyle=':')\n",
    "# #             ax1.set_xticks(np.arange(-0.5, 2.1, 0.5))\n",
    "# #             ax1.set_yticks(np.arange(-1, 2.1, 0.5))\n",
    "# #             ax1.set_xlim(x_min-0.5, x_max+0.5, auto=True)\n",
    "# #             ax1.set_ylim(y_min-0.5, y_max+0.5, auto=True)\n",
    "#             ax1.set_xlabel('Feature 1')\n",
    "#             ax1.set_ylabel('Feature 2')\n",
    "# #             ax1.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "# #             ax1.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "#             ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "#             ax2.scatter(x_real[:, 1], x_real[:, 2], x_real[:, 3], c='darkorange', alpha=0.5)\n",
    "#             ax2.scatter(x_fake[:, 1], x_fake[:, 2], x_fake[:, 3], c='navy', alpha=0.5)\n",
    "#             ax2.grid(linestyle=':')\n",
    "# #             ax2.set_xticks(np.arange(-0.5, 2.1, 0.5))\n",
    "# #             ax2.set_yticks(np.arange(-1, 2.1, 0.5))\n",
    "# #             ax2.set_zticks(np.arange(-3, 1.1, 1))\n",
    "# #             ax2.set_xlim(x_min-0.5, x_max+0.5, auto=True)\n",
    "# #             ax2.set_ylim(y_min-0.5, y_max+0.5, auto=True)\n",
    "# #             ax2.set_zlim(z_min-0.5, z_max+0.5, auto=True)\n",
    "#             ax2.set_xlabel('Feature 1')\n",
    "#             ax2.set_ylabel('Feature 2')\n",
    "#             ax2.set_zlabel('Feature 3')\n",
    "# #             ax2.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "# #             ax2.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "#             plt.suptitle(f'Epoch {i+1}')\n",
    "# #             plt.savefig(f'./augmentation/muller2019/epoch_{i+1}.jpg', bbox_inches='tight', pad_inches=0.1, dpi=150)\n",
    "# #             plt.close()\n",
    "#             plt.show()\n",
    "\n",
    "#         # plot accuracy\n",
    "#         # -------------\n",
    "#         x_real, x_fake, acc_real, acc_fake = summarize_performance(i, g_model, d_model, latent_dim)\n",
    "#         acc_real_all.append(acc_real)\n",
    "#         acc_fake_all.append(acc_fake)\n",
    "        \n",
    "#         if (i+1) % n_eval == 0:\n",
    "#             print(i+1, acc_real, acc_fake)\n",
    "    \n",
    "        if i == n_epochs-1:\n",
    "            # remove outliers\n",
    "            x_fake = x_fake[(np.abs(stats.zscore(x_fake)) < 3).all(axis=1)]\n",
    "            x_fake_ones = ones((x_fake.shape[0], 1))\n",
    "            x_fake = np.concatenate((x_fake, x_fake_ones), axis=1)\n",
    "            x_fake_num = x_fake.shape[0]\n",
    "            smote_gan_samples = np.concatenate((Xy_train_num, x_fake), axis=0)\n",
    "            smote_gan_samples = pd.DataFrame(smote_gan_samples, columns=num_features_list)\n",
    "#             smote_gan_samples = smote_gan_samples[(np.abs(stats.zscore(smote_gan_samples)) < 3).all(axis=1)]\n",
    "    \n",
    "    return smote_gan_samples, x_fake_num # acc_real_all, acc_fake_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d3300",
   "metadata": {},
   "source": [
    "### Single Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58744a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# size of the latent space\n",
    "latent_dim = int(features_num.shape[1]*0.5)\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator(features_num.shape[1])\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim, features_num.shape[1])\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# train model\n",
    "smote_gan_samples, x_fake_num = train(generator, discriminator, gan_model, latent_dim, n_epochs=10000)\n",
    "\n",
    "Xy_train = Xy_train.drop(index=Xy_train_out)\n",
    "Xy_train_cat = Xy_train[cat_features_list]\n",
    "Xy_train_cat_positive = Xy_train_positive[cat_features_list]\n",
    "Xy_train_cat_positive_mode = Xy_train_cat_positive.mode()\n",
    "Xy_train_cat_positive_mode = Xy_train_cat_positive_mode.loc[Xy_train_cat_positive_mode.index.repeat(x_fake_num)].reset_index(drop=True)\n",
    "Xy_train_cat = pd.concat([Xy_train_cat, Xy_train_cat_positive_mode]).reset_index(drop=True)\n",
    "smote_gan_samples = pd.concat([smote_gan_samples, Xy_train_cat], axis=1).reset_index(drop=True)\n",
    "smote_gan_samples = smote_gan_samples[features_label_list]\n",
    "smote_gan_samples.to_csv(f'./Datasets/Outputs/smote_gan.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ce9a6",
   "metadata": {},
   "source": [
    "### Multiple Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2bf9d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Iteration 1\n",
      "--------------------\n",
      "100 0.6384615302085876 0.856249988079071\n",
      "200 0.7589743733406067 0.925000011920929\n",
      "300 0.8153846263885498 0.8812500238418579\n",
      "400 0.9179487228393555 0.9125000238418579\n",
      "500 0.892307698726654 0.7749999761581421\n",
      "600 0.9179487228393555 0.7562500238418579\n",
      "700 0.9589743614196777 0.8062499761581421\n",
      "800 0.9358974099159241 0.75\n",
      "900 0.9358974099159241 0.8374999761581421\n",
      "1000 0.9564102292060852 0.856249988079071\n",
      "1100 0.9256410002708435 0.9312499761581421\n",
      "1200 0.9564102292060852 0.7562500238418579\n",
      "1300 0.892307698726654 0.731249988079071\n",
      "1400 0.7589743733406067 0.7250000238418579\n",
      "1500 0.7589743733406067 0.8125\n",
      "1600 0.7538461685180664 0.7875000238418579\n",
      "1700 0.7769230604171753 0.768750011920929\n",
      "1800 0.7461538314819336 0.862500011920929\n",
      "1900 0.6435897350311279 0.9312499761581421\n",
      "2000 0.7435897588729858 0.925000011920929\n",
      "2100 0.7948718070983887 0.9624999761581421\n",
      "2200 0.728205144405365 0.90625\n",
      "2300 0.7820512652397156 0.84375\n",
      "2400 0.8846153616905212 0.8500000238418579\n",
      "2500 0.8769230842590332 0.8500000238418579\n",
      "2600 0.8512820601463318 0.8999999761581421\n",
      "2700 0.8948717713356018 0.9312499761581421\n",
      "2800 0.9230769276618958 0.84375\n",
      "2900 0.8615384697914124 0.8999999761581421\n",
      "3000 0.9384615421295166 0.824999988079071\n",
      "3100 0.892307698726654 0.893750011920929\n",
      "3200 0.8358974456787109 0.9125000238418579\n",
      "3300 0.8051282167434692 0.8999999761581421\n",
      "3400 0.8282051086425781 0.8812500238418579\n",
      "3500 0.8717948794364929 0.90625\n",
      "3600 0.9230769276618958 0.90625\n",
      "3700 0.8384615182876587 0.90625\n",
      "3800 0.8333333134651184 0.8187500238418579\n",
      "3900 0.8230769038200378 0.8374999761581421\n",
      "4000 0.7846153974533081 0.949999988079071\n",
      "4100 0.7974358797073364 0.9125000238418579\n",
      "4200 0.8179486989974976 0.8374999761581421\n",
      "4300 0.8282051086425781 0.8062499761581421\n",
      "4400 0.8358974456787109 0.8812500238418579\n",
      "4500 0.8282051086425781 0.8812500238418579\n",
      "4600 0.8615384697914124 0.831250011920929\n",
      "4700 0.7871794700622559 0.9312499761581421\n",
      "4800 0.8230769038200378 0.8812500238418579\n",
      "4900 0.8282051086425781 0.8687499761581421\n",
      "5000 0.8282051086425781 0.84375\n",
      "--------------------\n",
      "Iteration 2\n",
      "--------------------\n",
      "100 0.8282051086425781 0.875\n",
      "200 0.8307692408561707 0.9125000238418579\n",
      "300 0.8282051086425781 0.8687499761581421\n",
      "400 0.8282051086425781 0.9125000238418579\n",
      "500 0.8256410360336304 0.893750011920929\n",
      "600 0.8307692408561707 0.8500000238418579\n",
      "700 0.8230769038200378 0.8500000238418579\n",
      "800 0.8205128312110901 0.862500011920929\n",
      "900 0.8102564215660095 0.956250011920929\n",
      "1000 0.800000011920929 0.856249988079071\n",
      "1100 0.8025640845298767 0.925000011920929\n",
      "1200 0.800000011920929 0.8812500238418579\n",
      "1300 0.8025640845298767 0.9375\n",
      "1400 0.800000011920929 0.9125000238418579\n",
      "1500 0.800000011920929 0.949999988079071\n",
      "1600 0.800000011920929 0.9312499761581421\n",
      "1700 0.800000011920929 0.925000011920929\n",
      "1800 0.800000011920929 0.956250011920929\n",
      "1900 0.800000011920929 0.956250011920929\n",
      "2000 0.800000011920929 0.949999988079071\n",
      "2100 0.800000011920929 0.981249988079071\n",
      "2200 0.800000011920929 0.949999988079071\n",
      "2300 0.8025640845298767 0.96875\n",
      "2400 0.800000011920929 0.9624999761581421\n",
      "2500 0.800000011920929 0.96875\n",
      "2600 0.800000011920929 0.96875\n",
      "2700 0.800000011920929 0.9312499761581421\n",
      "2800 0.800000011920929 0.9750000238418579\n",
      "2900 0.7974358797073364 0.9437500238418579\n",
      "3000 0.7974358797073364 0.9937499761581421\n",
      "3100 0.7974358797073364 0.96875\n",
      "3200 0.7974358797073364 0.90625\n",
      "3300 0.800000011920929 0.956250011920929\n",
      "3400 0.800000011920929 0.9624999761581421\n",
      "3500 0.7974358797073364 0.9624999761581421\n",
      "3600 0.7974358797073364 0.956250011920929\n",
      "3700 0.800000011920929 0.949999988079071\n",
      "3800 0.7948718070983887 0.918749988079071\n",
      "3900 0.7948718070983887 0.949999988079071\n",
      "4000 0.800000011920929 0.956250011920929\n",
      "4100 0.7974358797073364 0.9375\n",
      "4200 0.7948718070983887 0.893750011920929\n",
      "4300 0.7897436022758484 0.9750000238418579\n",
      "4400 0.7461538314819336 1.0\n",
      "4500 0.7948718070983887 0.925000011920929\n",
      "4600 0.7923076748847961 0.9624999761581421\n",
      "4700 0.7820512652397156 0.949999988079071\n",
      "4800 0.7743589878082275 0.9937499761581421\n",
      "4900 0.7794871926307678 0.9937499761581421\n",
      "5000 0.7461538314819336 1.0\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = int(features_num.shape[1]*0.5)\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator(features_num.shape[1])\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim, features_num.shape[1])\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "\n",
    "n_iter = 2\n",
    "acc_real_all = []\n",
    "acc_fake_all = []\n",
    "\n",
    "Xy_train = Xy_train.drop(index=Xy_train_out)\n",
    "Xy_train_cat = Xy_train[cat_features_list]\n",
    "Xy_train_cat_positive = Xy_train_positive[cat_features_list]\n",
    "Xy_train_cat_positive_mode = Xy_train_cat_positive.mode()\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print('--------------------')\n",
    "    print(f'Iteration {i+1}')\n",
    "    print('--------------------')\n",
    "    \n",
    "    # train model\n",
    "    smote_gan_samples, x_fake_num = train(generator, discriminator, gan_model, latent_dim, n_epochs=5000)\n",
    "    \n",
    "#     acc_real_all.append(acc_real)\n",
    "#     acc_fake_all.append(acc_fake)\n",
    "\n",
    "    Xy_train_cat_positive_mode_ = Xy_train_cat_positive_mode.loc[Xy_train_cat_positive_mode.index.repeat(x_fake_num)].reset_index(drop=True)\n",
    "    Xy_train_cat_ = pd.concat([Xy_train_cat, Xy_train_cat_positive_mode_]).reset_index(drop=True)\n",
    "    smote_gan_samples = pd.concat([smote_gan_samples, Xy_train_cat_], axis=1).reset_index(drop=True)\n",
    "    smote_gan_samples = smote_gan_samples[features_label_list]\n",
    "    smote_gan_samples.to_csv(f'./Datasets/Outputs/smote_gan_{i+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7398e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list = [f'./augmentation/muller2019/epoch_{i}.jpg' for i in range(100, 10001, 100)]\n",
    "clip = mpy.ImageSequenceClip(frame_list, fps=5)\n",
    "clip.write_gif('./augmentation/muller2019/epochs.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list = [f'./augmentation/muller2019/epoch_{i}.jpg' for i in range(100, 10001, 100)]\n",
    "images = []\n",
    "\n",
    "for frame in frame_list:\n",
    "    images.append(imageio.imread(frame))\n",
    "    \n",
    "imageio.mimsave('./augmentation/muller2019/epochs.gif', images, loop=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d496dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_gan_samples_file = f'./Datasets/Outputs/smote_gan.csv'\n",
    "smote_gan_samples = pd.read_csv(smote_gan_samples_file, index_col=False)\n",
    "\n",
    "def interactive_hist(df, columns, colorby=None):\n",
    "  \"\"\"Plots interactive histograms of a dataframe.\n",
    "  Input:\n",
    "    df: a pandas dataframe containing numerical columns\n",
    "    columns: list of columns within dataframe\n",
    "    colorby: column within dataframe to color data by\n",
    "  Output:\n",
    "    None\n",
    "  Jack Maughan\n",
    "  DATAROCK\n",
    "  Date: 2/5/2022\"\"\"\n",
    "\n",
    "  @interact(x=columns)\n",
    "  def update(x):\n",
    "      fig = px.histogram(df, x=x, nbins=100, color=colorby)\n",
    "      fig.update_layout(xaxis = dict(title=x+' Values'),\n",
    "                      yaxis = dict(title='Counts'),\n",
    "                      title = \"Distribution Data - \"+x,\n",
    "                      barmode='stack',    autosize=True,\n",
    "                      width=800, height=600)\n",
    "      fig.show('notebook')\n",
    "\n",
    "def plot_3D_scatter(df, columns, colorby=None):\n",
    "    \"\"\"Plots interactive 3D scatter plots of dataframes. Number of dataframes\n",
    "    in the list 'dfs' determines how many scatters are plotted (max. 6).\n",
    "    Input:\n",
    "    dfs: a list of pandas dataframes containing numerical columns\n",
    "    columns: list of columns within dataframe\n",
    "    subplot_titles: list of titles for each plot\n",
    "    colorby: array/pd.Series to colorby (numerical)\n",
    "    Output:\n",
    "    None\n",
    "    Jack Maughan\n",
    "    DATAROCK\n",
    "    Date: 2/5/2022\"\"\"\n",
    "    \n",
    "    df0 = df[df['color_label']==0]\n",
    "    df1 = df[df['color_label']==1]\n",
    "    df2 = df[df['color_label']==2]\n",
    "\n",
    "    @interact(x=columns, y=columns, z=columns)\n",
    "    def update(x, y, z):\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter3d(x=df0[columns][x], y=df0[columns][y], z=df0[columns][z], name ='Background', marker=dict(color = '#EF553B', size=6, line=dict(width=2, color='DarkSlateGrey')), mode='markers'))\n",
    "        fig.add_trace(go.Scatter3d(x=df1[columns][x], y=df1[columns][y], z=df1[columns][z], name = 'GAN Deposits', marker=dict(color = '#00CC96', size=6, line=dict(width=2, color='DarkSlateGrey')), mode='markers'))\n",
    "        fig.add_trace(go.Scatter3d(x=df2[columns][x], y=df2[columns][y], z=df2[columns][z], name = 'Actual Deposits', marker=dict(color = '#636EFA', size=6, line=dict(width=2, color='DarkSlateGrey')), mode='markers'))\n",
    "        \n",
    "        #Update layout to include axis titles\n",
    "        fig.update_layout(height=1200, width=1200, showlegend=True, scene1 = dict(xaxis_title=x, yaxis_title=y, zaxis_title=z))\n",
    "        fig.show('notebook')\n",
    "\n",
    "smote_gan_samples['color_label'] = smote_gan_samples['label']\n",
    "smote_gan_samples.loc[:36, 'color_label'] = 2\n",
    "interactive_hist(smote_gan_samples, smote_gan_samples.columns, colorby='color_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add13aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3D_scatter(smote_gan_samples, smote_gan_samples.columns, colorby=smote_gan_samples['color_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e920a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoenc_pip",
   "language": "python",
   "name": "autoenc_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
